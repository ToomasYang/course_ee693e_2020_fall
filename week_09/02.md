---
title: "02: [Fingerprinting Encrypted Voice Traffic on Smart Speakers with Deep Learning] by [C. Wang, S. Kennedy, H. Li, K. Hudson, G. Atluri, X. Wei, W. Sun, and B. Wang]"
date: 2020-10-21
type: book
commentable: true

# Provide the name of the presenter
summary: "Presenters: Brian Lu and Matthew Sahara"

# Provide other tags that describe the paper
tags:
- teaching
- ee693e
- wireless fingerprinting
- deep learning
---

***
## Paper Summary
[PROVIDE ONE PARAGRAPH SUMMARIZING OF THE PAPER (>100 WORDS)]
Smart speaker devices and systems are steadily growing in popularity across the globe. This featured work explores the application of fingerprinting on encrypted traffic of various smart speakers, using different types of neural networks. Data collection of network traffic is automated using a Raspberry Pi for the emulation of a voice command, alongside a smart speaker with an internet connection. Large datasets are generated from different popular smart speakers (Alexa, Echo) under closed-world and open-world conditions. Methods used for fingerprinting of encrypted traffic include: Convolutional Neural Network, Long Short-Term Memory, Stacked AutoEncoder, and Ensemble Learning.
***

## Presentation
{{< youtube YupirjAVxFU >}}
***

## Review
### Strengths
[SUMMARIZE THE STRENGTHS OF THE PAPER IN FULL SENTENCES (>50 WORDS)]
- [STRENGTHS 01]
- [STRENGTHS o1]

### Weaknesses
[SUMMARIZE THE WEAKNESSES OF THE PAPER IN FULL SENTENCES (>50 WORDS)]
- [WEAKNESSES 01]
- [WEAKNESSES o1]

### Detalied Comments
[PROVIDE DETAILED EXPLIANATION OF THE STRENGHS AND WEAKNESSES LISTED ABOVE (>
200 WORDS)]

### Implementation
[PROVIDE DETAILED EXPLIANATION OF THE CODES/DATA PROVIDED BY THE PAPER] (>
200 WORDS)]
[PROVIDE LINK(S) TO THE CODES/DATA PROVIDED BY THE PAPER](https://github.com/gustybear-teaching/course_ee693e_2020_fall)

### Experimentation
[PROVIDE FIGURES/TABLE/WRITTEN-PROOF FROM THE PAPER]

{{< figure src="https://github.com/gustybear-teaching/course_ee693e_2020_fall/raw/main/week_09/images/example.png" title="[RESULTS FROM THE PAPER]" width="300" >}}

[(OPTIONAL) PROVIDE FIGURES/TABLE/WRITTEN-PROOF FROM YOUR OWN EXPERIMENT]

{{< figure src="https://github.com/gustybear-teaching/course_ee693e_2020_fall/raw/main/week_09/images/example.png" title="[RESULTS FROM YOU]" width="300" >}}

[DISCUSS THE DIFFERENCES AND CAUSES BETWEEN RESULTS, IF ANY]

### Audience Questions

1. This paper mentioned that they could leverage packet timing, which they are interested for future work. How would this help improve experimental results?
2. Whether their attacks will be effective on human voices in the real world?
3. Can this technique be applied to other smart speakers made by different manufacturers?
4. Since a simple package padding would easily break the attack. Will this attack be economically viable?
5. What are some ways the obfsucation defence can be improved?
6. What can an attacker do to obtain more information after identifying the fingerprinting of those voice commands
7. Could this be trained to eventually fingerprint simple phrases that aren't also voice commands?
8. How would this attack fair in an ecosystem of different smart devices? What if the target had a variety of smart devices connected to the network?